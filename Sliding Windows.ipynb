{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c017b948",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "9407a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, BertForQuestionAnswering, BertTokenizer, DistilBertTokenizerFast, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "869773db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset doc2dial (./data_cache/doc2dial/dialogue_domain/1.0.1/c15afdf53780a8d6ebea7aec05384432195b356f879aa53a4ee39b740d520642)\n"
     ]
    }
   ],
   "source": [
    "split = \"train\"\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "dialogue_dataset = load_dataset(\n",
    "    \"doc2dial\",\n",
    "    name=\"dialogue_domain\",  # this is the name of the dataset for the second subtask, dialog generation\n",
    "    split=split,\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bdce100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset doc2dial (./data_cache/doc2dial/document_domain/1.0.1/c15afdf53780a8d6ebea7aec05384432195b356f879aa53a4ee39b740d520642)\n"
     ]
    }
   ],
   "source": [
    "document_dataset = load_dataset(\n",
    "    \"doc2dial\",\n",
    "    name=\"document_domain\",  # this is the name of the dataset for the second subtask, dialog generation\n",
    "    split=split,\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d09bea",
   "metadata": {},
   "source": [
    "## Creating the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b41ec8",
   "metadata": {},
   "source": [
    "Steps:\n",
    "- [X] Sliding windows from the Document\n",
    "- [ ] Extract user utterance\n",
    "- [ ] Extract Dialogue history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e67840f",
   "metadata": {},
   "source": [
    "### Sliding windows from the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "ec52a056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'DistilBertTokenizerFast'.\n",
      "0it [00:00, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "1it [00:00,  4.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the faulty character: {end_pos}\n",
      "This is the faulty character: {end_pos}\n",
      "This is the faulty character: {end_pos}\n",
      "This is the faulty character: {end_pos}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:01,  5.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the faulty character: {end_pos}\n",
      "This is the faulty character: {end_pos}\n",
      "This is the faulty character: {end_pos}\n",
      "This is the faulty character: {end_pos}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:02,  4.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 2.0558907985687256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Defining train_dict\n",
    "train_dict = dict()\n",
    "train_dict['train_document'] = []\n",
    "train_dict['train_id_sp'] = []\n",
    "train_dict['train_user_utterance'] = []\n",
    "train_dict['train_doc_domain'] = []\n",
    "train_dict['train_doc_id'] = []\n",
    "train_dict['train_text_sp'] = []\n",
    "train_dict['train_dial_id_turn_id'] = []     # necessary for evaluation\n",
    "train_dict['train_start_pos'] = []     \n",
    "train_dict['train_end_pos'] = []     \n",
    "train_dict['train_start_tok'] = []     \n",
    "train_dict['train_end_tok'] = []  \n",
    "\n",
    "start = time.time()\n",
    "for idx, dialogue in tqdm(enumerate(dialogue_dataset)):\n",
    "    if idx == 10:\n",
    "        break\n",
    "    dial_id_turn_id = []       # running list of <dial_id>_<turn_id> for evaluation\n",
    "    sp_id_list = []            # running list of spans per document\n",
    "    user_utterance_list = []   # running list of user utterances per document\n",
    "    \n",
    "    for turn in dialogue['turns']:\n",
    "        dial_id_turn_id.append(dialogue['dial_id'] + '_' + str(turn['turn_id']))\n",
    "        if turn['role'] == 'user':\n",
    "            # TURN UTTERANCE IS FLATTENED AND ONLY THE [INPUT_IDS] IS STORED\n",
    "            turn['utterance'] = tokenizer(turn['utterance'], padding=True, truncation=True, return_tensors=\"pt\")['input_ids'].view(-1)\n",
    "            user_utterance_list.append(turn['utterance'])   # adding user utterance to user_utterance_list\n",
    "        else:\n",
    "            references = turn['references']\n",
    "            ref_sp_id = []\n",
    "            for ref in references:\n",
    "                ref_sp_id.append(ref['sp_id'])\n",
    "            sp_id_list.append(ref_sp_id)          # adding list of sp_ids per dialogue to list of sp_ids per document\n",
    "    train_dict['train_id_sp'].append(sp_id_list)\n",
    "    train_dict['train_user_utterance'].append(user_utterance_list)\n",
    "    train_dict['train_doc_domain'].append(dialogue['domain'])\n",
    "    train_dict['train_doc_id'].append(dialogue['doc_id'])\n",
    "    train_dict['train_dial_id_turn_id'].append(dial_id_turn_id)\n",
    "    \n",
    "    for doc in document_dataset:\n",
    "        if doc['doc_id'] == train_dict['train_doc_id'][-1]:\n",
    "            # DOCUMENT TEXT IS NOT A TENSOR. PREVIOUSLY WE HAD tokenizer( )['index_ids'].view(-1)\n",
    "            doc['doc_text'] = tokenizer(doc['doc_text'], padding=True, truncation=False, return_tensors=\"pt\")\n",
    "            train_dict['train_document'].append(doc['doc_text'])          # adding the total document text\n",
    "            text_sp_2 = []            \n",
    "            start_sp_list = []         # big start sp list\n",
    "            end_sp_list = []           # big end sp list        \n",
    "            start_tok_list = []         # big start token list\n",
    "            end_tok_list = []           # big end token list     \n",
    "            for train_spans_id in train_dict['train_id_sp'][-1]:    \n",
    "                text_sp = \"\"         \n",
    "                ref_start_pos_list = []\n",
    "                ref_end_pos_list = []      \n",
    "                for span in doc['spans']:                    \n",
    "                    if span['id_sp'] in train_spans_id:\n",
    "                        text_sp += span['text_sp']                        \n",
    "                        ref_start_pos_list.append(span['start_sp'])\n",
    "                        ref_end_pos_list.append(span['end_sp'])    \n",
    "                start_pos = np.amin(ref_start_pos_list)\n",
    "                start_sp_list.append(start_pos)\n",
    "                # convert start_pos to start_token\n",
    "                start_tok_pos = doc['doc_text'].char_to_token(start_pos)\n",
    "                # check that start_tok_pos is not None\n",
    "                start_tok_list.append(start_tok_pos)\n",
    "                # convert end_pos to end_token\n",
    "                end_pos = np.amax(ref_end_pos_list)\n",
    "                end_sp_list.append(end_pos)\n",
    "                end_tok_pos = doc['doc_text'].char_to_token(end_pos)\n",
    "                while end_tok_pos == None:\n",
    "                    print('This is the faulty character: {end_pos}')\n",
    "                    end_pos = end_pos - 1\n",
    "                    end_tok_pos = doc['doc_text'].char_to_token(end_pos)\n",
    "                    print('This is the faulty character: {end_pos}')\n",
    "                end_tok_list.append(end_tok_pos)\n",
    "                text_sp_2.append(text_sp)\n",
    "            train_dict['train_text_sp'].append(text_sp_2)\n",
    "            train_dict['train_start_pos'].append(start_sp_list)\n",
    "            train_dict['train_end_pos'].append(end_sp_list)\n",
    "            train_dict['train_start_tok'].append(start_tok_list)\n",
    "            train_dict['train_end_tok'].append(end_tok_list)\n",
    "            break\n",
    "end = time.time()\n",
    "print(f'Total time: {end-start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd5fc1d",
   "metadata": {},
   "source": [
    "Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f173f9",
   "metadata": {},
   "source": [
    "# Functions for Dataset / Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "cc0b781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_mask(question, text):\n",
    "    '''   \n",
    "    text['input_ids'].view(-1)[1:] was on the line below where 'text' is now - \n",
    "    need to do this to text before sending it into this function\n",
    "    \n",
    "    input_ids: will be the question and the window of the document concat together\n",
    "    segment_ids: is a mask that makes the two sentences distinct 1's for question 0 for document text\n",
    "    '''\n",
    "    input_ids=torch.cat((question, text), 0)\n",
    "    SEP_token_id=102\n",
    "    sep_idx = (input_ids == 102).nonzero(as_tuple=False)[0][0].item()\n",
    "    num_seg_a = sep_idx+1\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "    return input_ids, segment_ids\n",
    "\n",
    "def add_sep_tokens(windows):\n",
    "    tmp = []\n",
    "    sep_token = 102\n",
    "    for window in windows:\n",
    "        end = len(window) - 1\n",
    "        if window[end] != sep_token:\n",
    "            # add a SEP token at the end\n",
    "            tmp.append(torch.cat((window, torch.tensor([102])),0))\n",
    "        else:\n",
    "            tmp.append(window)\n",
    "    return tmp\n",
    "\n",
    "def sliding_windows(question, document, start_token=None, end_token=None, stride=256):\n",
    "    # tokenized input_ids is the document - remove [CLS] before sending through   \n",
    "    # TODO: if start_token and end_token != None, check that the context contains the answer. \n",
    "    # This is only used during training \n",
    "    windows = []\n",
    "    model_tok_limit = 511  # model can take 512 tokens maximum - -1 to add a sep token at end of each window\n",
    "    start = 0\n",
    "    end = model_tok_limit - len(question)\n",
    "    doc_size = len(document)\n",
    "        \n",
    "    # handling edge case of documents smaller than models input (512 tokens)   \n",
    "    if len(document) <= model_tok_limit:\n",
    "        end = len(document)\n",
    "    \n",
    "    while(start <= doc_size):\n",
    "        # print(start, end, doc_size)\n",
    "        training = (start_token != None and end_token != None) \n",
    "        question_length=len(question)\n",
    "        if training:     # check that question is inside the context\n",
    "            question_inside_context = (start_token >= start and end_token <= end)\n",
    "        if (not training) or (training and question_inside_context):\n",
    "            # if not training or answer inside the context\n",
    "            window = document[start:end]\n",
    "            windows.append(window)\n",
    "        \n",
    "        if end == doc_size: \n",
    "            break\n",
    "        \n",
    "        start += stride\n",
    "        # if there are less tokens than the slide amount\n",
    "        if (doc_size - (start + stride)) < stride:\n",
    "            end = doc_size\n",
    "        else:\n",
    "            end += stride\n",
    "    \n",
    "    windows = add_sep_tokens(windows)\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13828a3",
   "metadata": {},
   "source": [
    "Create mask for start and end positions. This way we only check the first token after the '.' as start positions, and the tokens before the '.' as end positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e49803a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded question: [CLS] can i do my dmv transactions online? [SEP]\n"
     ]
    }
   ],
   "source": [
    "question=train_dict['train_user_utterance'][0][1]\n",
    "print(f'Decoded question: {tokenizer.decode(question)}')\n",
    "# If already tokenized from dataset\n",
    "text=train_dict['train_document'][0]    # tokenized text\n",
    "# if simple text\n",
    "#text='By statute , you must report a change of address to DMV within ten days of moving. That is the case for the address associated with your license, as well as all the addresses associated with each registered vehicle, which may differ.'\n",
    "#text=tokenizer([text],  return_tensors=\"pt\")['input_ids'].view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8b07c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Sliding Window [1:] to remove the [CLS] that was put in by the tokenizer\n",
    "    The Model likes '[CLS] Sentence1 [SEP] Sentence2 [SEP]' it doesn't need the [CLS]\n",
    "'''\n",
    "windows = []\n",
    "windows = sliding_windows(question, text['input_ids'][0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "78260b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "512\n",
      "433\n"
     ]
    }
   ],
   "source": [
    "for window in windows:\n",
    "    print(len(window) + len(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "92fb1f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = []\n",
    "\n",
    "for window in windows:\n",
    "    model_inputs.append(text_mask(question, window))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "63f9e0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_inputs[2][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f797a61d",
   "metadata": {},
   "source": [
    "## Our Model - BertForQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c8430278",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "93eb219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for model_input in model_inputs:\n",
    "    output = model(model_input[0].view(1,-1), token_type_ids=torch.tensor([model_input[1]]))\n",
    "    models.append([model_input, output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d76782",
   "metadata": {},
   "source": [
    "model_outputs contains a list of [input, output]\n",
    "\n",
    "    output is the models output\n",
    "\n",
    "    input is a list containing [input_ids, segment_ids]\n",
    "\n",
    "        -input_ids is a tokenized input\n",
    "\n",
    "        -segment_ids is a mask to let the model understand there are two individual sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c945813e",
   "metadata": {},
   "source": [
    "## Functions for after the model has been run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66a0d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token id for '.' = 1012\n",
    "def mask_start_end(input_ids_trunc, segment_ids_trunc, mode):\n",
    "    \"\"\"Returns a mask for the start and end logits. \n",
    "    input_ids_trunc = tokens (tensor)\n",
    "    segment_ids_trunc = mask (question / text)\n",
    "    mode = \"start\" or 'end'\n",
    "    return tensor\n",
    "    \"\"\"\n",
    "    a = torch.where(input_ids_trunc == 1012, 1, 0)   # mask=1 for '.'\n",
    "    a = a * torch.tensor(segment_ids_trunc)          # mask question - text\n",
    "    if mode=='start':\n",
    "        b = torch.cat((torch.tensor([0]),a),0)[:-1]     # move the 1s one position to the right\n",
    "    else:\n",
    "        b = torch.cat((a, torch.tensor([0])),0)[1:]\n",
    "    assert len (a) == len(b)\n",
    "    return b\n",
    "\n",
    "def tensor_to_positive(tensor, mask):\n",
    "    \"\"\" All the values need to be higher than 0, since 0s are values for the mask\n",
    "    and we don't want to choose them when selecting the start or end token.\n",
    "    Return torch.tensor \"\"\"\n",
    "    min_value = torch.amin(tensor) \n",
    "    tensor_positive = tensor + (mask * np.abs(min_value.detach().numpy()))\n",
    "    return tensor_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "01cad9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer start: 416, Answer end: 360\n",
      "Answer start: 160, Answer end: 104\n",
      "Answer start: 373, Answer end: 371\n",
      "I am unable to find the answer to this question. Can you please ask another question?\n",
      "\n",
      "Question:\n",
      "[CLS] can i do my dmv transactions online? [SEP]\n",
      "\n",
      "Answer:\n",
      "forgetting to update address by statute , you must report a change of address to d ##m ##v within ten days of moving.\n"
     ]
    }
   ],
   "source": [
    "model_joint_probability = []\n",
    "\n",
    "# picked a low number \n",
    "sum_joint_prob = -1000\n",
    "best_tokens = None\n",
    "answer_start = None\n",
    "answer_end = None\n",
    "\n",
    "# calculate the best combined (start+end) probability from each window. Use the best probability as the output\n",
    "# from the model\n",
    "\n",
    "for m in models:\n",
    "    # TODO: check that the context is inside the window\n",
    "    model_tokens = tokenizer.convert_ids_to_tokens(m[0][0])\n",
    "    mask_start = mask_start_end(m[0][0], m[0][1], 'start') # [0][0] = input_ids [0][1] = segment_ids\n",
    "    start_logits_positive = tensor_to_positive(m[1].start_logits * mask_start, mask_start)\n",
    "    model_answer_start = torch.argmax(start_logits_positive)  # token index for the highest start token\n",
    "    max_start_prob = m[1].start_logits[0][model_answer_start].item()\n",
    "    \n",
    "    mask_end = mask_start_end(m[0][0], m[0][1], 'end')\n",
    "    end_logits_positive = tensor_to_positive(m[1].end_logits * mask_end, mask_end)\n",
    "    model_answer_end = torch.argmax(end_logits_positive)\n",
    "    max_end_prob = m[1].end_logits[0][model_answer_end].item()\n",
    "    \n",
    "    model_joint_prob = max_start_prob + max_end_prob\n",
    "    \n",
    "    if model_joint_prob > sum_joint_prob:\n",
    "        sum_joint_prob = model_joint_prob\n",
    "        tokens = model_tokens\n",
    "        answer_start = model_answer_start\n",
    "        answer_end = model_answer_end\n",
    "\n",
    "if answer_end >= answer_start:\n",
    "    answer = \" \".join(tokens[answer_start:answer_end+1])\n",
    "else:\n",
    "    print(\"I am unable to find the answer to this question. Can you please ask another question?\")\n",
    "    \n",
    "print(\"\\nQuestion:\\n{}\".format(tokenizer.decode(question)))\n",
    "print(\"\\nAnswer:\\n{}.\".format(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f985b4",
   "metadata": {},
   "source": [
    "## Fine-tune our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0041b6",
   "metadata": {},
   "source": [
    "This is what they do at HuggingFace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81314be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87c765dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/Users/ri21540/.cache/huggingface/datasets/squad/plain_text/1.0.0/6b6c4172d0119c74515f44ea0b8262efe4897f2ddb6613e5e915840fdc309c16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b699754637c469e9f1cff244b37389d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ddb3b7961ca4ccf80921cf55c6cc348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "squad = load_dataset(\"squad\")\n",
    "tokenized_squad = squad.map(preprocess_function, batched=True, remove_columns=squad[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "64fca119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tokenized_squad['train'][0]['input_ids'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca5b301",
   "metadata": {},
   "source": [
    "### Dataset creation following HuggingFace format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "4e408a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "0d43831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_input(input_ids, segment_ids):\n",
    "    if len(input_ids) < 512:\n",
    "        pad_input = torch.tensor(np.zeros(512 - len(input_ids)))\n",
    "        input_ids = torch.cat((input_ids, pad_input), 0)\n",
    "        pad_segment = torch.tensor(np.ones(512 - len(segment_ids)))\n",
    "        segment_ids = torch.cat((torch.tensor(segment_ids), pad_segment), 0)\n",
    "    return input_ids, segment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "aaeded2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]/var/folders/yl/kyjv_cpj1j70_ry0q6699fbh0000gq/T/ipykernel_3884/3483503398.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data['attention_mask'].append(torch.tensor(segment_ids).to(torch.int64))\n",
      "100%|██████████████████████████████████████████| 10/10 [00:00<00:00, 685.31it/s]\n"
     ]
    }
   ],
   "source": [
    "data = dict()\n",
    "data['input_ids'] = []\n",
    "data['attention_mask'] = []\n",
    "data['start_positions'] = []\n",
    "data['end_positions'] = []\n",
    "\n",
    "for idx_dialogue in tqdm(range(0, len(train_dict['train_document']))):      # num dialogues\n",
    "    utterances = train_dict['train_user_utterance'][idx_dialogue]\n",
    "    document = train_dict['train_document'][idx_dialogue]\n",
    "    for idx_utterance, utterance in enumerate(utterances):\n",
    "        start_token = train_dict['train_start_tok'][idx_dialogue][idx_utterance]\n",
    "        end_token = train_dict['train_end_tok'][idx_dialogue][idx_utterance]\n",
    "#         print(f'Idx dialogue: {idx_dialogue}, Idx utterance: {idx_utterance} -------------------')\n",
    "        windows = sliding_windows(utterance, document['input_ids'][0][1:], start_token, end_token)\n",
    "#         print(f'{start_token}, {end_token}, {len(windows)}')\n",
    "#         print(f'Start token: {start_token}\\nEnd token: {end_token}\\nUtterance: {tokenizer.decode(utterance)}\\nWindow length: {len(windows)}\\n\\n')\n",
    "        for window in windows:\n",
    "            input_ids, segment_ids = text_mask(utterance, window)\n",
    "            input_ids, segment_ids = pad_input(input_ids, segment_ids)\n",
    "            data['input_ids'].append(input_ids.to(torch.int64).to(device))\n",
    "            data['attention_mask'].append(torch.tensor(segment_ids).to(torch.int64).to(device))\n",
    "            data['start_positions'].append(start_token)\n",
    "            data['end_positions'].append(end_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "9684c438",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_training = OurDataset(data)\n",
    "dataset_validation = OurDataset(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3b8f8a",
   "metadata": {},
   "source": [
    "We want to freeze the first 60% of the hidden layers: <br>\n",
    "[:-79] = 60%\n",
    "[:-2] = 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb9c5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in list(model.named_parameters()): \n",
    "    print(f'{name}') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "16764167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will be frozen: bert.embeddings.word_embeddings.weight\n",
      "I will be frozen: bert.embeddings.position_embeddings.weight\n",
      "I will be frozen: bert.embeddings.token_type_embeddings.weight\n",
      "I will be frozen: bert.embeddings.LayerNorm.weight\n",
      "I will be frozen: bert.embeddings.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.0.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.0.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.0.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.0.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.0.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.0.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.1.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.1.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.1.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.1.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.1.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.1.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.2.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.2.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.2.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.2.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.2.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.2.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.3.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.3.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.3.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.3.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.3.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.3.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.4.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.4.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.4.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.4.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.4.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.4.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.5.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.5.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.5.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.5.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.5.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.5.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.6.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.6.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.6.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.6.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.6.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.6.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.7.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.7.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.7.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.7.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.7.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.7.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.8.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.8.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.8.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.8.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.8.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.8.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.8.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.8.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.9.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.9.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.9.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.9.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.9.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.9.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.9.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.9.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.10.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.10.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.10.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.10.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.10.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.10.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.10.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.10.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.10.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.10.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.10.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.10.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.10.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.10.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.11.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.11.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.11.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.11.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.11.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.11.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.11.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.11.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.11.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.11.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.11.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.11.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.11.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.11.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.12.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.12.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.12.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.12.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.12.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.12.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.12.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.12.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.12.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.12.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.12.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.12.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.12.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.12.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.12.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.12.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.13.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.13.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.13.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.13.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.13.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.13.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.13.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.13.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.13.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.13.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.13.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.13.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.13.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.13.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.13.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.13.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.14.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.14.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.14.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.14.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.14.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.14.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.14.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.14.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.14.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.14.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.14.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.14.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.14.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.14.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.14.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.14.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.15.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.15.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.15.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.15.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.15.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.15.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.15.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.15.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.15.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.15.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.15.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.15.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.15.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.15.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.15.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.15.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.16.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.16.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.16.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.16.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.16.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.16.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.16.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.16.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.16.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.16.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.16.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.16.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.16.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.16.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.16.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.16.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.17.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.17.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.17.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.17.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.17.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.17.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.17.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.17.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.17.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.17.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.17.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.17.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.17.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.17.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.17.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.17.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.18.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.18.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.18.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.18.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.18.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.18.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.18.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.18.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.18.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.18.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.18.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.18.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.18.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.18.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.18.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.18.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.19.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.19.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.19.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.19.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.19.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.19.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.19.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.19.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.19.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.19.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.19.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.19.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.19.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.19.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.19.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.19.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.20.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.20.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.20.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.20.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.20.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.20.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.20.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.20.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.20.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.20.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.20.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.20.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.20.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.20.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.20.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.20.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.21.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.21.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.21.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.21.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.21.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.21.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.21.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.21.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.21.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.21.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.21.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.21.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.21.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.21.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.21.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.21.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.22.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.22.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.22.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.22.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.22.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.22.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.22.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.22.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.22.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.22.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.22.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.22.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.22.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.22.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.22.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.22.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.23.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.23.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.23.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.23.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.23.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.23.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.23.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.23.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.23.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.23.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.23.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.23.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.23.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.23.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.23.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.23.output.LayerNorm.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in list(model.named_parameters())[:-2]: \n",
    "    print('I will be frozen: {}'.format(name)) \n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "9a762a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import default_data_collator\n",
    "data_collator = default_data_collator\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_training,\n",
    "    eval_dataset=dataset_validation,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "afcbb3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 08:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.769510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.767421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.766675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 83\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 83\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 83\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18, training_loss=5.331610361735026, metrics={'train_runtime': 558.6488, 'train_samples_per_second': 0.446, 'train_steps_per_second': 0.032, 'total_flos': 231248041039872.0, 'train_loss': 5.331610361735026, 'epoch': 3.0})"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588f1e4a",
   "metadata": {},
   "source": [
    "### Output - For Report\n",
    "\n",
    "This section of text shows that span [49][50][51][52] is what we return. However, the section belows is what the ground truth says. SPan [51] is highlighted in red (we return 51, ground truth doesn't contain it).\n",
    "\n",
    "- 'About ten percent of customers visiting a DMV office do not bring what they need to complete their transaction, and have to come back a second time to finish their business. This can be as simple as not bringing sufficient funds to pay for a license renewal or not having the proof of auto insurance required to register a car. <font color='red'>Better yet ,</font> don t visit a DMV office at all, and see if your transaction can be performed online, like an address change, registration renewal, license renewal, replacing a lost title, paying a DRA or scheduling a road test. '\n",
    "- 'About ten percent of customers visiting a DMV office do not bring what they need to complete their transaction, and have to come back a second time to finish their business. This can be as simple as not bringing sufficient funds to pay for a license renewal or not having the proof of auto insurance required to register a car. don t visit a DMV office at all, and see if your transaction can be performed online, like an address change, registration renewal, license renewal, replacing a lost title, paying a DRA or scheduling a road test. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed44f31d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
