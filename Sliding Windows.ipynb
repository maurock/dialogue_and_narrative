{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c017b948",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "id": "9407a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, BertForQuestionAnswering, BertTokenizer, DistilBertTokenizerFast, AutoModelForQuestionAnswering, TrainingArguments, Trainer\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "869773db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset doc2dial (./data_cache/doc2dial/dialogue_domain/1.0.1/c15afdf53780a8d6ebea7aec05384432195b356f879aa53a4ee39b740d520642)\n"
     ]
    }
   ],
   "source": [
    "split = \"train\"\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "dialogue_dataset = load_dataset(\n",
    "    \"doc2dial\",\n",
    "    name=\"dialogue_domain\",  # this is the name of the dataset for the second subtask, dialog generation\n",
    "    split=split,\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "5bdce100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset doc2dial (./data_cache/doc2dial/document_domain/1.0.1/c15afdf53780a8d6ebea7aec05384432195b356f879aa53a4ee39b740d520642)\n"
     ]
    }
   ],
   "source": [
    "document_dataset = load_dataset(\n",
    "    \"doc2dial\",\n",
    "    name=\"document_domain\",  # this is the name of the dataset for the second subtask, dialog generation\n",
    "    split=split,\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d09bea",
   "metadata": {},
   "source": [
    "## Creating the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b41ec8",
   "metadata": {},
   "source": [
    "Steps:\n",
    "- [X] Sliding windows from the Document\n",
    "- [ ] Extract user utterance\n",
    "- [ ] Extract Dialogue history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e67840f",
   "metadata": {},
   "source": [
    "### Sliding windows from the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "ec52a056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /Users/ri21540/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /Users/ri21540/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /Users/ri21540/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /Users/ri21540/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.11.2\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'DistilBertTokenizerFast'.\n",
      "0it [00:00, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "84it [00:16,  5.22it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/yl/kyjv_cpj1j70_ry0q6699fbh0000gq/T/ipykernel_3884/287388099.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mtrain_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_dial_id_turn_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdial_id_turn_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'doc_id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtrain_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train_doc_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0;31m# DOCUMENT TEXT IS NOT A TENSOR. PREVIOUSLY WE HAD tokenizer( )['index_ids'].view(-1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/dialogue_narrative/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1264\u001b[0m         \u001b[0moutput_all_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output_all_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1266\u001b[0;31m             yield self._getitem(\n\u001b[0m\u001b[1;32m   1267\u001b[0m                 \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1268\u001b[0m                 \u001b[0mformat_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/dialogue_narrative/lib/python3.9/site-packages/datasets/arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[0;34m(self, key, format_type, format_columns, output_all_columns, format_kwargs)\u001b[0m\n\u001b[1;32m   1508\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_formatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1509\u001b[0m         \u001b[0mpa_subtable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1510\u001b[0;31m         formatted_output = format_table(\n\u001b[0m\u001b[1;32m   1511\u001b[0m             \u001b[0mpa_subtable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_all_columns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1512\u001b[0m         )\n",
      "\u001b[0;32m~/miniforge3/envs/dialogue_narrative/lib/python3.9/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_table\u001b[0;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[1;32m    412\u001b[0m     \u001b[0mpython_formatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mformat_columns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquery_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/dialogue_narrative/lib/python3.9/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pa_table, query_type)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mRowFormat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mColumnFormat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchFormat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"row\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"column\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/dialogue_narrative/lib/python3.9/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mformat_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFormatter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_arrow_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mformat_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/dialogue_narrative/lib/python3.9/site-packages/datasets/formatting/formatting.py\u001b[0m in \u001b[0;36mextract_row\u001b[0;34m(self, pa_table)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mPythonArrowExtractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseArrowExtractor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_row\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_unnest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pydict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextract_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Defining train_dict\n",
    "train_dict = dict()\n",
    "train_dict['train_document'] = []\n",
    "train_dict['train_id_sp'] = []\n",
    "train_dict['train_user_utterance'] = []\n",
    "train_dict['train_doc_domain'] = []\n",
    "train_dict['train_doc_id'] = []\n",
    "train_dict['train_text_sp'] = []\n",
    "train_dict['train_dial_id_turn_id'] = []     # necessary for evaluation\n",
    "train_dict['train_start_pos'] = []     \n",
    "train_dict['train_end_pos'] = []     \n",
    "train_dict['train_start_tok'] = []     \n",
    "train_dict['train_end_tok'] = []  \n",
    "train_dict['train_all_utterances'] = []\n",
    "\n",
    "start = time.time()\n",
    "for idx, dialogue in tqdm(enumerate(dialogue_dataset)):\n",
    "    #if idx == 100:\n",
    "    #    break\n",
    "    dial_id_turn_id = []       # running list of <dial_id>_<turn_id> for evaluation\n",
    "    sp_id_list = []            # running list of spans per document\n",
    "    user_utterance_list = []   # running list of user utterances per document\n",
    "    all_utterances_list = []\n",
    "    for idx_turn, turn in enumerate(dialogue['turns']):\n",
    "        dial_id_turn_id.append(dialogue['dial_id'] + '_' + str(turn['turn_id']))\n",
    "        all_utterances_list.append(turn['utterance'])\n",
    "        if turn['role'] == 'user':            \n",
    "            # If the previous turn was still the user, we want to concatenate the \n",
    "            # current and previous utterances\n",
    "            if idx_turn > 0 and dialogue['turns'][idx_turn-1]['role'] == 'user':\n",
    "                turn['utterance'] = tokenizer(turn['utterance'], padding=True, truncation=True, return_tensors=\"pt\")['input_ids'].view(-1)[1:]\n",
    "                previous_utterance = user_utterance_list[-1][:-1]  # the previous utterance ends with [SEP], we remove it\n",
    "                turn['utterance'] = torch.cat((previous_utterance, turn['utterance']), 0)\n",
    "                user_utterance_list[-1]= turn['utterance']  # replace last element in list\n",
    "            else:\n",
    "              # TURN UTTERANCE IS FLATTENED AND ONLY THE [INPUT_IDS] IS STORED\n",
    "              turn['utterance'] = tokenizer(turn['utterance'], padding=True, truncation=True, return_tensors=\"pt\")['input_ids'].view(-1)\n",
    "              user_utterance_list.append(turn['utterance'])   # adding user utterance to user_utterance_list\n",
    "        else:\n",
    "            references = turn['references']\n",
    "            ref_sp_id = []\n",
    "            for ref in references:\n",
    "                ref_sp_id.append(ref['sp_id'])\n",
    "            sp_id_list.append(ref_sp_id)          # adding list of sp_ids per dialogue to list of sp_ids per document\n",
    "\n",
    "    train_dict['train_id_sp'].append(sp_id_list)\n",
    "    train_dict['train_user_utterance'].append(user_utterance_list)\n",
    "    train_dict['train_all_utterances'].append(all_utterances_list)\n",
    "    train_dict['train_doc_domain'].append(dialogue['domain'])\n",
    "    train_dict['train_doc_id'].append(dialogue['doc_id'])\n",
    "    train_dict['train_dial_id_turn_id'].append(dial_id_turn_id)\n",
    "    \n",
    "    for doc in document_dataset:\n",
    "        if doc['doc_id'] == train_dict['train_doc_id'][-1]:\n",
    "            # DOCUMENT TEXT IS NOT A TENSOR. PREVIOUSLY WE HAD tokenizer( )['index_ids'].view(-1)\n",
    "            doc['doc_text'] = tokenizer(doc['doc_text'], padding=True, truncation=False, return_tensors=\"pt\")\n",
    "            train_dict['train_document'].append(doc['doc_text'])          # adding the total document text\n",
    "            text_sp_2 = []            \n",
    "            start_sp_list = []         # big start sp list\n",
    "            end_sp_list = []           # big end sp list        \n",
    "            start_tok_list = []         # big start token list\n",
    "            end_tok_list = []           # big end token list     \n",
    "            for train_spans_id in train_dict['train_id_sp'][-1]:    \n",
    "                text_sp = \"\"         \n",
    "                ref_start_pos_list = []\n",
    "                ref_end_pos_list = []      \n",
    "                for span in doc['spans']:                    \n",
    "                    if span['id_sp'] in train_spans_id:\n",
    "                        text_sp += span['text_sp']                        \n",
    "                        ref_start_pos_list.append(span['start_sp'])\n",
    "                        ref_end_pos_list.append(span['end_sp'])    \n",
    "                start_pos = np.amin(ref_start_pos_list)\n",
    "                start_sp_list.append(start_pos)\n",
    "                # convert start_pos to start_token\n",
    "                start_tok_pos = doc['doc_text'].char_to_token(start_pos)\n",
    "                # check that start_tok_pos is not None, if it is go to the next character\n",
    "                while start_tok_pos == None:\n",
    "                    start_pos = start_pos + 1\n",
    "                    start_tok_pos = doc['doc_text'].char_to_token(start_pos)\n",
    "                start_tok_list.append(start_tok_pos)\n",
    "                # convert end_pos to end_token\n",
    "                end_pos = np.amax(ref_end_pos_list)\n",
    "                end_sp_list.append(end_pos)\n",
    "                end_tok_pos = doc['doc_text'].char_to_token(end_pos)\n",
    "                # check that end_tok_pos is not None, if it is go to the next character\n",
    "                while end_tok_pos == None:\n",
    "                    end_pos = end_pos - 1\n",
    "                    end_tok_pos = doc['doc_text'].char_to_token(end_pos)\n",
    "                end_tok_list.append(end_tok_pos)\n",
    "                text_sp_2.append(text_sp)\n",
    "            train_dict['train_text_sp'].append(text_sp_2)\n",
    "            train_dict['train_start_pos'].append(start_sp_list)\n",
    "            train_dict['train_end_pos'].append(end_sp_list)\n",
    "            train_dict['train_start_tok'].append(start_tok_list)\n",
    "            train_dict['train_end_tok'].append(end_tok_list)\n",
    "            break\n",
    "end = time.time()\n",
    "print(f'Total time: {end-start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd5fc1d",
   "metadata": {},
   "source": [
    "Results:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f173f9",
   "metadata": {},
   "source": [
    "# Functions for Dataset / Sliding Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "cc0b781d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_mask(question, text):\n",
    "    '''   \n",
    "    text['input_ids'].view(-1)[1:] was on the line below where 'text' is now - \n",
    "    need to do this to text before sending it into this function\n",
    "    \n",
    "    input_ids: will be the question and the window of the document concat together\n",
    "    segment_ids: is a mask that makes the two sentences distinct 1's for question 0 for document text\n",
    "    '''\n",
    "    input_ids=torch.cat((question, text), 0)\n",
    "    SEP_token_id=102\n",
    "    sep_idx = (input_ids == 102).nonzero(as_tuple=False)[0][0].item()\n",
    "    num_seg_a = sep_idx+1\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "    return input_ids, segment_ids\n",
    "\n",
    "def add_sep_tokens(windows):\n",
    "    tmp = []\n",
    "    sep_token = 102\n",
    "    for window in windows:\n",
    "        end = len(window) - 1\n",
    "        if window[end] != sep_token:\n",
    "            # add a SEP token at the end\n",
    "            tmp.append(torch.cat((window, torch.tensor([102])),0))\n",
    "        else:\n",
    "            tmp.append(window)\n",
    "    return tmp\n",
    "\n",
    "def sliding_windows(question, document, start_token=None, end_token=None, stride=256):\n",
    "    # tokenized input_ids is the document - remove [CLS] before sending through   \n",
    "    # TODO: if start_token and end_token != None, check that the context contains the answer. \n",
    "    # This is only used during training \n",
    "    windows = []\n",
    "    model_tok_limit = 511  # model can take 512 tokens maximum - -1 to add a sep token at end of each window\n",
    "    start = 0\n",
    "    end = model_tok_limit - len(question)\n",
    "    doc_size = len(document)\n",
    "        \n",
    "    # handling edge case of documents smaller than models input (512 tokens)   \n",
    "    if len(document) <= model_tok_limit:\n",
    "        end = len(document)\n",
    "    \n",
    "    while(start <= doc_size):\n",
    "        # print(start, end, doc_size)\n",
    "        training = (start_token != None and end_token != None) \n",
    "        question_length=len(question)\n",
    "        if training:     # check that question is inside the context\n",
    "            question_inside_context = (start_token >= start and end_token <= end)\n",
    "        if (not training) or (training and question_inside_context):\n",
    "            # if not training or answer inside the context\n",
    "            window = document[start:end]\n",
    "            windows.append(window)\n",
    "        \n",
    "        if end == doc_size: \n",
    "            break\n",
    "        \n",
    "        start += stride\n",
    "        # if there are less tokens than the slide amount\n",
    "        if (doc_size - (start + stride)) < stride:\n",
    "            end = doc_size\n",
    "        else:\n",
    "            end += stride\n",
    "    \n",
    "    windows = add_sep_tokens(windows)\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13828a3",
   "metadata": {},
   "source": [
    "Create mask for start and end positions. This way we only check the first token after the '.' as start positions, and the tokens before the '.' as end positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e49803a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded question: [CLS] can i do my dmv transactions online? [SEP]\n"
     ]
    }
   ],
   "source": [
    "question=train_dict['train_user_utterance'][0][1]\n",
    "print(f'Decoded question: {tokenizer.decode(question)}')\n",
    "# If already tokenized from dataset\n",
    "text=train_dict['train_document'][0]    # tokenized text\n",
    "# if simple text\n",
    "#text='By statute , you must report a change of address to DMV within ten days of moving. That is the case for the address associated with your license, as well as all the addresses associated with each registered vehicle, which may differ.'\n",
    "#text=tokenizer([text],  return_tensors=\"pt\")['input_ids'].view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "8b07c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Sliding Window [1:] to remove the [CLS] that was put in by the tokenizer\n",
    "    The Model likes '[CLS] Sentence1 [SEP] Sentence2 [SEP]' it doesn't need the [CLS]\n",
    "'''\n",
    "windows = []\n",
    "windows = sliding_windows(question, text['input_ids'][0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "78260b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n",
      "512\n",
      "433\n"
     ]
    }
   ],
   "source": [
    "for window in windows:\n",
    "    print(len(window) + len(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "92fb1f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = []\n",
    "\n",
    "for window in windows:\n",
    "    model_inputs.append(text_mask(question, window))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "63f9e0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "433"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_inputs[2][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f797a61d",
   "metadata": {},
   "source": [
    "## Our Model - BertForQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c8430278",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "93eb219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for model_input in model_inputs:\n",
    "    output = model(model_input[0].view(1,-1), token_type_ids=torch.tensor([model_input[1]]))\n",
    "    models.append([model_input, output])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d76782",
   "metadata": {},
   "source": [
    "model_outputs contains a list of [input, output]\n",
    "\n",
    "    output is the models output\n",
    "\n",
    "    input is a list containing [input_ids, segment_ids]\n",
    "\n",
    "        -input_ids is a tokenized input\n",
    "\n",
    "        -segment_ids is a mask to let the model understand there are two individual sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c945813e",
   "metadata": {},
   "source": [
    "## Functions for after the model has been run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66a0d597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token id for '.' = 1012\n",
    "def mask_start_end(input_ids_trunc, segment_ids_trunc, mode):\n",
    "    \"\"\"Returns a mask for the start and end logits. \n",
    "    input_ids_trunc = tokens (tensor)\n",
    "    segment_ids_trunc = mask (question / text)\n",
    "    mode = \"start\" or 'end'\n",
    "    return tensor\n",
    "    \"\"\"\n",
    "    a = torch.where(input_ids_trunc == 1012, 1, 0)   # mask=1 for '.'\n",
    "    a = a * torch.tensor(segment_ids_trunc)          # mask question - text\n",
    "    if mode=='start':\n",
    "        b = torch.cat((torch.tensor([0]),a),0)[:-1]     # move the 1s one position to the right\n",
    "    else:\n",
    "        b = torch.cat((a, torch.tensor([0])),0)[1:]\n",
    "    assert len (a) == len(b)\n",
    "    return b\n",
    "\n",
    "def tensor_to_positive(tensor, mask):\n",
    "    \"\"\" All the values need to be higher than 0, since 0s are values for the mask\n",
    "    and we don't want to choose them when selecting the start or end token.\n",
    "    Return torch.tensor \"\"\"\n",
    "    min_value = torch.amin(tensor) \n",
    "    tensor_positive = tensor + (mask * np.abs(min_value.detach().numpy()))\n",
    "    return tensor_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "01cad9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer start: 416, Answer end: 360\n",
      "Answer start: 160, Answer end: 104\n",
      "Answer start: 373, Answer end: 371\n",
      "I am unable to find the answer to this question. Can you please ask another question?\n",
      "\n",
      "Question:\n",
      "[CLS] can i do my dmv transactions online? [SEP]\n",
      "\n",
      "Answer:\n",
      "forgetting to update address by statute , you must report a change of address to d ##m ##v within ten days of moving.\n"
     ]
    }
   ],
   "source": [
    "model_joint_probability = []\n",
    "\n",
    "# picked a low number \n",
    "sum_joint_prob = -1000\n",
    "best_tokens = None\n",
    "answer_start = None\n",
    "answer_end = None\n",
    "\n",
    "# calculate the best combined (start+end) probability from each window. Use the best probability as the output\n",
    "# from the model\n",
    "\n",
    "for m in models:\n",
    "    # TODO: check that the context is inside the window\n",
    "    model_tokens = tokenizer.convert_ids_to_tokens(m[0][0])\n",
    "    mask_start = mask_start_end(m[0][0], m[0][1], 'start') # [0][0] = input_ids [0][1] = segment_ids\n",
    "    start_logits_positive = tensor_to_positive(m[1].start_logits * mask_start, mask_start)\n",
    "    model_answer_start = torch.argmax(start_logits_positive)  # token index for the highest start token\n",
    "    max_start_prob = m[1].start_logits[0][model_answer_start].item()\n",
    "    \n",
    "    mask_end = mask_start_end(m[0][0], m[0][1], 'end')\n",
    "    end_logits_positive = tensor_to_positive(m[1].end_logits * mask_end, mask_end)\n",
    "    model_answer_end = torch.argmax(end_logits_positive)\n",
    "    max_end_prob = m[1].end_logits[0][model_answer_end].item()\n",
    "    \n",
    "    model_joint_prob = max_start_prob + max_end_prob\n",
    "    \n",
    "    if model_joint_prob > sum_joint_prob:\n",
    "        sum_joint_prob = model_joint_prob\n",
    "        tokens = model_tokens\n",
    "        answer_start = model_answer_start\n",
    "        answer_end = model_answer_end\n",
    "\n",
    "if answer_end >= answer_start:\n",
    "    answer = \" \".join(tokens[answer_start:answer_end+1])\n",
    "else:\n",
    "    print(\"I am unable to find the answer to this question. Can you please ask another question?\")\n",
    "    \n",
    "print(\"\\nQuestion:\\n{}\".format(tokenizer.decode(question)))\n",
    "print(\"\\nAnswer:\\n{}.\".format(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f985b4",
   "metadata": {},
   "source": [
    "## Fine-tune our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb0041b6",
   "metadata": {},
   "source": [
    "This is what they do at HuggingFace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81314be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    questions = [q.strip() for q in examples[\"question\"]]\n",
    "    inputs = tokenizer(\n",
    "        questions,\n",
    "        examples[\"context\"],\n",
    "        max_length=384,\n",
    "        truncation=\"only_second\",\n",
    "        return_offsets_mapping=True,\n",
    "        padding=\"max_length\",\n",
    "    )\n",
    "\n",
    "    offset_mapping = inputs.pop(\"offset_mapping\")\n",
    "    answers = examples[\"answers\"]\n",
    "    start_positions = []\n",
    "    end_positions = []\n",
    "\n",
    "    for i, offset in enumerate(offset_mapping):\n",
    "        answer = answers[i]\n",
    "        start_char = answer[\"answer_start\"][0]\n",
    "        end_char = answer[\"answer_start\"][0] + len(answer[\"text\"][0])\n",
    "        sequence_ids = inputs.sequence_ids(i)\n",
    "\n",
    "        # Find the start and end of the context\n",
    "        idx = 0\n",
    "        while sequence_ids[idx] != 1:\n",
    "            idx += 1\n",
    "        context_start = idx\n",
    "        while sequence_ids[idx] == 1:\n",
    "            idx += 1\n",
    "        context_end = idx - 1\n",
    "\n",
    "        # If the answer is not fully inside the context, label it (0, 0)\n",
    "        if offset[context_start][0] > end_char or offset[context_end][1] < start_char:\n",
    "            start_positions.append(0)\n",
    "            end_positions.append(0)\n",
    "        else:\n",
    "            # Otherwise it's the start and end token positions\n",
    "            idx = context_start\n",
    "            while idx <= context_end and offset[idx][0] <= start_char:\n",
    "                idx += 1\n",
    "            start_positions.append(idx - 1)\n",
    "\n",
    "            idx = context_end\n",
    "            while idx >= context_start and offset[idx][1] >= end_char:\n",
    "                idx -= 1\n",
    "            end_positions.append(idx + 1)\n",
    "\n",
    "    inputs[\"start_positions\"] = start_positions\n",
    "    inputs[\"end_positions\"] = end_positions\n",
    "    return inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87c765dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (/Users/ri21540/.cache/huggingface/datasets/squad/plain_text/1.0.0/6b6c4172d0119c74515f44ea0b8262efe4897f2ddb6613e5e915840fdc309c16)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b699754637c469e9f1cff244b37389d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ddb3b7961ca4ccf80921cf55c6cc348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "squad = load_dataset(\"squad\")\n",
    "tokenized_squad = squad.map(preprocess_function, batched=True, remove_columns=squad[\"train\"].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "id": "64fca119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 469,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_squad['train'][0]['start_positions']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca5b301",
   "metadata": {},
   "source": [
    "### Dataset creation following HuggingFace format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "4e408a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OurDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "0d43831c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_input(input_ids, segment_ids):\n",
    "    if len(input_ids) < 512:\n",
    "        pad_input = torch.tensor(np.zeros(512 - len(input_ids)))\n",
    "        input_ids = torch.cat((input_ids, pad_input), 0)\n",
    "        pad_segment = torch.tensor(np.ones(512 - len(segment_ids)))\n",
    "        segment_ids = torch.cat((torch.tensor(segment_ids), pad_segment), 0)\n",
    "    return input_ids, segment_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "id": "aaeded2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/10 [00:00<?, ?it/s]/var/folders/yl/kyjv_cpj1j70_ry0q6699fbh0000gq/T/ipykernel_3884/3483503398.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data['attention_mask'].append(torch.tensor(segment_ids).to(torch.int64))\n",
      "100%|██████████████████████████████████████████| 10/10 [00:00<00:00, 685.31it/s]\n"
     ]
    }
   ],
   "source": [
    "data = dict()\n",
    "data['input_ids'] = []\n",
    "data['attention_mask'] = []\n",
    "data['start_positions'] = []\n",
    "data['end_positions'] = []\n",
    "\n",
    "for idx_dialogue in tqdm(range(0, len(train_dict['train_document']))):      # num dialogues\n",
    "    utterances = train_dict['train_user_utterance'][idx_dialogue]\n",
    "    document = train_dict['train_document'][idx_dialogue]\n",
    "    for idx_utterance, utterance in enumerate(utterances):\n",
    "        start_token = train_dict['train_start_tok'][idx_dialogue][idx_utterance]\n",
    "        end_token = train_dict['train_end_tok'][idx_dialogue][idx_utterance]\n",
    "#         print(f'Idx dialogue: {idx_dialogue}, Idx utterance: {idx_utterance} -------------------')\n",
    "        windows = sliding_windows(utterance, document['input_ids'][0][1:], start_token, end_token)\n",
    "#         print(f'{start_token}, {end_token}, {len(windows)}')\n",
    "#         print(f'Start token: {start_token}\\nEnd token: {end_token}\\nUtterance: {tokenizer.decode(utterance)}\\nWindow length: {len(windows)}\\n\\n')\n",
    "        for window in windows:\n",
    "            input_ids, segment_ids = text_mask(utterance, window)\n",
    "            input_ids, segment_ids = pad_input(input_ids, segment_ids)\n",
    "            data['input_ids'].append(input_ids.to(torch.int64).to(device))\n",
    "            data['attention_mask'].append(torch.tensor(segment_ids).to(torch.int64).to(device))\n",
    "            data['start_positions'].append(start_token)\n",
    "            data['end_positions'].append(end_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "9684c438",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_training = OurDataset(data)\n",
    "dataset_validation = OurDataset(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3b8f8a",
   "metadata": {},
   "source": [
    "We want to freeze the first 60% of the hidden layers: <br>\n",
    "[:-79] = 60%\n",
    "[:-2] = 99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb9c5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in list(model.named_parameters()): \n",
    "    print(f'{name}') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "16764167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will be frozen: bert.embeddings.word_embeddings.weight\n",
      "I will be frozen: bert.embeddings.position_embeddings.weight\n",
      "I will be frozen: bert.embeddings.token_type_embeddings.weight\n",
      "I will be frozen: bert.embeddings.LayerNorm.weight\n",
      "I will be frozen: bert.embeddings.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.0.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.0.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.0.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.0.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.0.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.0.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.1.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.1.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.1.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.1.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.1.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.1.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.2.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.2.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.2.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.2.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.2.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.2.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.3.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.3.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.3.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.3.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.3.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.3.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.4.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.4.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.4.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.4.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.4.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.4.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.5.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.5.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.5.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.5.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.5.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.5.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.6.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.6.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.6.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.6.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.6.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.6.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.7.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.7.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.7.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.7.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.7.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.7.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.8.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.8.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.8.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.8.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.8.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.8.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.8.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.8.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.8.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.9.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.9.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.9.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.9.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.9.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.9.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.9.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.9.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.9.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.10.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.10.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.10.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.10.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.10.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.10.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.10.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.10.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.10.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.10.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.10.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.10.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.10.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.10.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.11.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.11.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.11.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.11.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.11.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.11.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.11.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.11.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.11.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.11.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.11.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.11.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.11.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.11.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.12.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.12.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.12.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.12.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.12.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.12.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.12.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.12.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.12.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.12.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.12.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.12.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.12.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.12.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.12.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.12.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.13.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.13.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.13.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.13.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.13.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.13.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.13.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.13.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.13.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.13.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.13.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.13.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.13.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.13.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.13.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.13.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.14.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.14.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.14.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.14.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.14.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.14.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.14.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.14.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.14.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.14.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.14.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.14.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.14.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.14.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.14.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.14.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.15.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.15.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.15.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.15.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.15.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.15.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.15.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.15.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.15.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.15.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.15.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.15.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.15.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.15.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.15.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.15.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.16.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.16.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.16.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.16.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.16.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.16.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.16.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.16.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.16.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.16.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.16.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.16.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.16.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.16.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.16.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.16.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.17.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.17.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.17.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.17.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.17.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.17.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.17.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.17.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.17.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.17.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.17.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.17.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.17.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.17.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.17.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.17.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.18.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.18.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.18.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.18.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.18.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.18.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.18.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.18.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.18.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.18.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.18.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.18.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.18.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.18.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.18.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.18.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.19.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.19.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.19.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.19.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.19.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.19.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.19.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.19.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.19.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.19.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.19.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.19.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.19.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.19.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.19.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.19.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.20.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.20.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.20.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.20.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.20.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.20.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.20.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.20.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.20.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.20.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.20.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.20.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.20.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.20.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.20.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.20.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.21.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.21.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.21.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.21.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.21.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.21.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.21.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.21.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.21.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.21.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.21.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.21.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.21.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.21.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.21.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.21.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.22.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.22.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.22.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.22.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.22.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.22.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.22.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.22.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.22.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.22.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.22.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.22.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.22.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.22.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.22.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.22.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.23.attention.self.query.weight\n",
      "I will be frozen: bert.encoder.layer.23.attention.self.query.bias\n",
      "I will be frozen: bert.encoder.layer.23.attention.self.key.weight\n",
      "I will be frozen: bert.encoder.layer.23.attention.self.key.bias\n",
      "I will be frozen: bert.encoder.layer.23.attention.self.value.weight\n",
      "I will be frozen: bert.encoder.layer.23.attention.self.value.bias\n",
      "I will be frozen: bert.encoder.layer.23.attention.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.23.attention.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.23.attention.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.23.attention.output.LayerNorm.bias\n",
      "I will be frozen: bert.encoder.layer.23.intermediate.dense.weight\n",
      "I will be frozen: bert.encoder.layer.23.intermediate.dense.bias\n",
      "I will be frozen: bert.encoder.layer.23.output.dense.weight\n",
      "I will be frozen: bert.encoder.layer.23.output.dense.bias\n",
      "I will be frozen: bert.encoder.layer.23.output.LayerNorm.weight\n",
      "I will be frozen: bert.encoder.layer.23.output.LayerNorm.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in list(model.named_parameters())[:-2]: \n",
    "    print('I will be frozen: {}'.format(name)) \n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "9a762a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    }
   ],
   "source": [
    "from transformers import default_data_collator\n",
    "data_collator = default_data_collator\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset_training,\n",
    "    eval_dataset=dataset_validation,\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "afcbb3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 83\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='18' max='18' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [18/18 08:54, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.769510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.767421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>5.766675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 83\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 83\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 83\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=18, training_loss=5.331610361735026, metrics={'train_runtime': 558.6488, 'train_samples_per_second': 0.446, 'train_steps_per_second': 0.032, 'total_flos': 231248041039872.0, 'train_loss': 5.331610361735026, 'epoch': 3.0})"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40de8b36",
   "metadata": {},
   "source": [
    "## Get document text and user utterance from id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "id": "73c145dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9f44c1539efe6f7e79b02eb1b413aa43_1     for example\n",
    "def id_to_doc_utterance(search_element):\n",
    "    for idx_dialogue, dialogue in enumerate(train_dict['train_dial_id_turn_id']):\n",
    "        for idx_turn, dial_id_turn_id in enumerate(dialogue):\n",
    "            if dial_id_turn_id == search_element:\n",
    "                print(f'Dialogue index: {idx_dialogue}, Turn id: {idx_turn}')\n",
    "                doc = train_dict['train_document'][idx_dialogue]\n",
    "                utterance = train_dict['train_all_utterances'][idx_dialogue][idx_turn]\n",
    "    return doc, utterance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588f1e4a",
   "metadata": {},
   "source": [
    "### Output - For Report\n",
    "\n",
    "This section of text shows that span [49][50][51][52] is what we return. However, the section belows is what the ground truth says. SPan [51] is highlighted in red (we return 51, ground truth doesn't contain it).\n",
    "\n",
    "- 'About ten percent of customers visiting a DMV office do not bring what they need to complete their transaction, and have to come back a second time to finish their business. This can be as simple as not bringing sufficient funds to pay for a license renewal or not having the proof of auto insurance required to register a car. <font color='red'>Better yet ,</font> don t visit a DMV office at all, and see if your transaction can be performed online, like an address change, registration renewal, license renewal, replacing a lost title, paying a DRA or scheduling a road test. '\n",
    "- 'About ten percent of customers visiting a DMV office do not bring what they need to complete their transaction, and have to come back a second time to finish their business. This can be as simple as not bringing sufficient funds to pay for a license renewal or not having the proof of auto insurance required to register a car. don t visit a DMV office at all, and see if your transaction can be performed online, like an address change, registration renewal, license renewal, replacing a lost title, paying a DRA or scheduling a road test. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed44f31d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
