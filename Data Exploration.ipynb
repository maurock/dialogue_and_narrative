{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c017b948",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9407a603",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import pipeline\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import BertForQuestionAnswering\n",
    "from transformers import BertTokenizer\n",
    "from transformers import DistilBertTokenizerFast\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "869773db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset doc2dial (./data_cache/doc2dial/dialogue_domain/1.0.1/c15afdf53780a8d6ebea7aec05384432195b356f879aa53a4ee39b740d520642)\n"
     ]
    }
   ],
   "source": [
    "split = \"train\"\n",
    "cache_dir = \"./data_cache\"\n",
    "\n",
    "dialogue_dataset = load_dataset(\n",
    "    \"doc2dial\",\n",
    "    name=\"dialogue_domain\",  # this is the name of the dataset for the second subtask, dialog generation\n",
    "    split=split,\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bdce100",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset doc2dial (./data_cache/doc2dial/document_domain/1.0.1/c15afdf53780a8d6ebea7aec05384432195b356f879aa53a4ee39b740d520642)\n"
     ]
    }
   ],
   "source": [
    "document_dataset = load_dataset(\n",
    "    \"doc2dial\",\n",
    "    name=\"document_domain\",  # this is the name of the dataset for the second subtask, dialog generation\n",
    "    split=split,\n",
    "    ignore_verifications=True,\n",
    "    cache_dir=cache_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1219d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "dialogue_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7f019f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "document_dataset[250]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4385243",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_domain = 'dmv'\n",
    "search_doc_id = 'Top 5 DMV Mistakes and How to Avoid Them#3_0'\n",
    "search_id_sp = ['6', '7']\n",
    "\n",
    "def text_from_spans(search_domain, search_doc_id, search_id_sp, document_dataset):\n",
    "    start = time.time()\n",
    "    total_answer = ''\n",
    "    for doc in document_dataset:\n",
    "        if doc['domain'] == search_domain and doc['doc_id'] == search_doc_id:\n",
    "            for span in doc['spans']:\n",
    "                if span['id_sp'] in search_id_sp:\n",
    "                    total_answer+=span['text_sp']\n",
    "            break\n",
    "    print(f\"Time elapsed: {time.time() - start}\")\n",
    "    return total_answer\n",
    "\n",
    "text_from_spans(search_domain, search_doc_id, search_id_sp, document_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d09bea",
   "metadata": {},
   "source": [
    "## Creating the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b41ec8",
   "metadata": {},
   "source": [
    "Steps:\n",
    "- [X] Sliding windows from the Document\n",
    "- [ ] Extract user utterance\n",
    "- [ ] Extract Dialogue history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e67840f",
   "metadata": {},
   "source": [
    "### Sliding windows from the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec52a056",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
      "The class this function is called from is 'DistilBertTokenizerFast'.\n",
      "0it [00:00, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "10it [00:03,  3.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 3.030385971069336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Defining train_dict\n",
    "train_dict = dict()\n",
    "train_dict['train_document'] = []\n",
    "train_dict['train_id_sp'] = []\n",
    "train_dict['train_user_utterance'] = []\n",
    "train_dict['train_doc_domain'] = []\n",
    "train_dict['train_doc_id'] = []\n",
    "train_dict['train_text_sp'] = []\n",
    "train_dict['train_dial_id_turn_id'] = []     # necessary for evaluation\n",
    "train_dict['train_start_pos'] = []     \n",
    "train_dict['train_end_pos'] = []     \n",
    "train_dict['train_start_tok'] = []     \n",
    "train_dict['train_end_tok'] = []  \n",
    "\n",
    "start = time.time()\n",
    "for idx, dialogue in tqdm(enumerate(dialogue_dataset)):\n",
    "    if idx == 10:\n",
    "        break\n",
    "    dial_id_turn_id = []       # running list of <dial_id>_<turn_id> for evaluation\n",
    "    sp_id_list = []            # running list of spans per document\n",
    "    user_utterance_list = []   # running list of user utterances per document\n",
    "    \n",
    "    for turn in dialogue['turns']:\n",
    "        dial_id_turn_id.append(dialogue['dial_id'] + '_' + str(turn['turn_id']))\n",
    "        if turn['role'] == 'user':\n",
    "            # TURN UTTERANCE IS FLATTENED AND ONLY THE [INPUT_IDS] IS STORED\n",
    "            turn['utterance'] = tokenizer(turn['utterance'], padding=True, truncation=True, return_tensors=\"pt\")['input_ids'].view(-1)\n",
    "            user_utterance_list.append(turn['utterance'])   # adding user utterance to user_utterance_list\n",
    "        else:\n",
    "            references = turn['references']\n",
    "            ref_sp_id = []\n",
    "            for ref in references:\n",
    "                ref_sp_id.append(ref['sp_id'])\n",
    "            sp_id_list.append(ref_sp_id)          # adding list of sp_ids per dialogue to list of sp_ids per document\n",
    "    train_dict['train_id_sp'].append(sp_id_list)\n",
    "    train_dict['train_user_utterance'].append(user_utterance_list)\n",
    "    train_dict['train_doc_domain'].append(dialogue['domain'])\n",
    "    train_dict['train_doc_id'].append(dialogue['doc_id'])\n",
    "    train_dict['train_dial_id_turn_id'].append(dial_id_turn_id)\n",
    "    \n",
    "    for doc in document_dataset:\n",
    "        if doc['doc_id'] == train_dict['train_doc_id'][-1]:\n",
    "            # DOCUMENT TEXT IS NOT A TENSOR. PREVIOUSLY WE HAD tokenizer( )['index_ids'].view(-1)\n",
    "            doc['doc_text'] = tokenizer(doc['doc_text'], padding=True, truncation=False, return_tensors=\"pt\")\n",
    "            train_dict['train_document'].append(doc['doc_text'])          # adding the total document text\n",
    "            text_sp_2 = []            \n",
    "            start_sp_list = []         # big start sp list\n",
    "            end_sp_list = []           # big end sp list        \n",
    "            start_tok_list = []         # big start token list\n",
    "            end_tok_list = []           # big end token list     \n",
    "            for train_spans_id in train_dict['train_id_sp'][-1]:    \n",
    "                text_sp = \"\"         \n",
    "                ref_start_pos_list = []\n",
    "                ref_end_pos_list = []      \n",
    "                for span in doc['spans']:                    \n",
    "                    if span['id_sp'] in train_spans_id:\n",
    "                        text_sp += span['text_sp']                        \n",
    "                        ref_start_pos_list.append(span['start_sp'])\n",
    "                        ref_end_pos_list.append(span['end_sp'])    \n",
    "                start_pos = np.amin(ref_start_pos_list)\n",
    "                start_sp_list.append(start_pos)\n",
    "                # convert start_pos to start_token\n",
    "                start_tok_pos = doc['doc_text'].char_to_token(start_pos)\n",
    "                start_tok_list.append(start_tok_pos)\n",
    "                # convert end_pos to end_token\n",
    "                end_pos = np.amax(ref_end_pos_list)\n",
    "                end_sp_list.append(end_pos)\n",
    "                end_tok_pos = doc['doc_text'].char_to_token(end_pos)\n",
    "                end_tok_list.append(end_tok_pos)\n",
    "                text_sp_2.append(text_sp)\n",
    "            train_dict['train_text_sp'].append(text_sp_2)\n",
    "            train_dict['train_start_pos'].append(start_sp_list)\n",
    "            train_dict['train_end_pos'].append(end_sp_list)\n",
    "            train_dict['train_start_tok'].append(start_tok_list)\n",
    "            train_dict['train_end_tok'].append(end_tok_list)\n",
    "            break\n",
    "end = time.time()\n",
    "print(f'Total time: {end-start}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd5fc1d",
   "metadata": {},
   "source": [
    "Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033f590f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('User utterances:')\n",
    "print(train_dict['train_user_utterance'][0])\n",
    "\n",
    "print('\\nID Sp:')\n",
    "print(train_dict['train_id_sp'][0])\n",
    "\n",
    "print('\\nDoc ID:')\n",
    "print(train_dict['train_doc_id'][0])\n",
    "\n",
    "print('\\nDoc domain:')\n",
    "print(train_dict['train_doc_domain'][0])\n",
    "\n",
    "print('\\nTrain text spans:')\n",
    "print(train_dict['train_text_sp'][0])\n",
    "\n",
    "print('\\nDial_ID Turn_ID:')\n",
    "print(train_dict['train_dial_id_turn_id'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254a8616",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nDoc text:')\n",
    "print(train_dict['train_document'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86e18443",
   "metadata": {},
   "source": [
    "## Create a Dataframe out of the train_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211d7b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(train_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dba8f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"squad_v2\")\n",
    "print(metric.features) #this shows you what format the metric is expecting\n",
    "\n",
    "prediction = {'id': <rc dataset is of shape dialid_turnid - this value has to match the answer>,\n",
    "              'prediction_text': <your prediction>,\n",
    "              'no_answer_probability': 0.0} #edwin said we can ignore this for task 1\n",
    "reference = {'id': <see prediction>, \n",
    "              'answers': {\n",
    "                  'text': [list of answer, best to use the ones from the rc dataset],                                       \n",
    "                  'answer_start': [list of numbers of the answer star char again see rc dataset. ]}\n",
    "            }\n",
    "\n",
    "metric.add(prediction=prediction, reference=reference)\n",
    "final_score = metric.compute()\n",
    "final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f173f9",
   "metadata": {},
   "source": [
    "# Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fb18fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BertForQuestionAnswering.from_pretrained('bert-large-uncased-whole-word-masking-finetuned-squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc0b781d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decoded question: [CLS] hello, i forgot o update my address, can you help me with that? [SEP]\n"
     ]
    }
   ],
   "source": [
    "question=train_dict['train_user_utterance'][0][0]\n",
    "print(f'Decoded question: {tokenizer.decode(question)}')\n",
    "# If already tokenized from dataset\n",
    "text=train_dict['train_document'][0]    # tokenized text\n",
    "# if simple text\n",
    "#text='By statute , you must report a change of address to DMV within ten days of moving. That is the case for the address associated with your license, as well as all the addresses associated with each registered vehicle, which may differ.'\n",
    "#text=tokenizer([text],  return_tensors=\"pt\")['input_ids'].view(-1)\n",
    "\n",
    "def text_mask(question, text):\n",
    "    '''   \n",
    "    text['input_ids'].view(-1)[1:] was on the line below where 'text' is now - \n",
    "    need to do this to text before sending it into this function\n",
    "    \n",
    "    input_ids: will be the question and the window of the document concat together\n",
    "    segment_ids: is a mask that makes the two sentences distinct 1's for question 0 for document text\n",
    "    '''\n",
    "    input_ids=torch.cat((question, text), 0)\n",
    "    SEP_token_id=102\n",
    "    sep_idx = (input_ids == 102).nonzero(as_tuple=False)[0][0].item()\n",
    "    num_seg_a = sep_idx+1\n",
    "    num_seg_b = len(input_ids) - num_seg_a\n",
    "    segment_ids = [0]*num_seg_a + [1]*num_seg_b\n",
    "    assert len(segment_ids) == len(input_ids)\n",
    "    return input_ids, segment_ids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13828a3",
   "metadata": {},
   "source": [
    "Create mask for start and end positions. This way we only check the first token after the '.' as start positions, and the tokens before the '.' as end positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbff54e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token id for '.' = 1012\n",
    "def mask_start_end(input_ids_trunc, segment_ids_trunc, mode):\n",
    "    \"\"\"Returns a mask for the start and end logits. \n",
    "    input_ids_trunc = tokens (tensor)\n",
    "    segment_ids_trunc = mask (question / text)\n",
    "    mode = \"start\" or 'end'\n",
    "    return tensor\n",
    "    \"\"\"\n",
    "    a = torch.where(input_ids_trunc == 1012, 1, 0)   # mask=1 for '.'\n",
    "    a = a * torch.tensor(segment_ids_trunc)          # mask question - text\n",
    "    if mode=='start':\n",
    "        b = torch.cat((torch.tensor([0]),a),0)[:-1]     # move the 1s one position to the right\n",
    "    else:\n",
    "        b = torch.cat((a, torch.tensor([0])),0)[1:]\n",
    "    assert len (a) == len(b)\n",
    "    return b\n",
    "\n",
    "def tensor_to_positive(tensor, mask):\n",
    "    \"\"\" All the values need to be higher than 0, since 0s are values for the mask\n",
    "    and we don't want to choose them when selecting the start or end token.\n",
    "    Return torch.tensor \"\"\"\n",
    "    min_value = torch.amin(tensor) \n",
    "    tensor_positive = tensor + (mask * np.abs(min_value.detach().numpy()))\n",
    "    return tensor_positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3f4dad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f45a7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids_trunc = input_ids[:511]\n",
    "input_ids_trunc = torch.cat((input_ids_trunc, torch.tensor([102])),0)\n",
    "segment_ids_trunc = segment_ids[:512]\n",
    "\n",
    "output = model(input_ids_trunc.view(1,-1), token_type_ids=torch.tensor([segment_ids_trunc]))\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids_trunc)   # table with token_id -> word\n",
    "#tokens with highest start and end scores\n",
    "mask_start = mask_start_end(input_ids_trunc, segment_ids_trunc, 'start')\n",
    "start_logits_positive = tensor_to_positive(output.start_logits * mask_start, mask_start)\n",
    "answer_start = torch.argmax(start_logits_positive)  # token index for the highest start token\n",
    "max_start_prob = output.start_logits[0][answer_start].item()\n",
    "mask_end = mask_start_end(input_ids_trunc, segment_ids_trunc, 'end')\n",
    "end_logits_positive = tensor_to_positive(output.end_logits * mask_end, mask_end)\n",
    "answer_end = torch.argmax(end_logits_positive)\n",
    "max_end_prob = output.end_logits[0][answer_end].item()\n",
    "sum_joint_prob = max_start_prob + max_end_prob\n",
    "if answer_end >= answer_start:\n",
    "    answer = \" \".join(tokens[answer_start:answer_end+1])\n",
    "else:\n",
    "    print(\"I am unable to find the answer to this question. Can you please ask another question?\")\n",
    "    \n",
    "print(\"\\nQuestion:\\n{}\".format(tokenizer.decode(question)))\n",
    "print(\"\\nAnswer:\\n{}.\".format(answer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce30b584",
   "metadata": {},
   "source": [
    "### Output - For Report\n",
    "\n",
    "This section of text shows that span [49][50][51][52] is what we return. However, the section belows is what the ground truth says. SPan [51] is highlighted in red (we return 51, ground truth doesn't contain it).\n",
    "\n",
    "- 'About ten percent of customers visiting a DMV office do not bring what they need to complete their transaction, and have to come back a second time to finish their business. This can be as simple as not bringing sufficient funds to pay for a license renewal or not having the proof of auto insurance required to register a car. <font color='red'>Better yet ,</font> don t visit a DMV office at all, and see if your transaction can be performed online, like an address change, registration renewal, license renewal, replacing a lost title, paying a DRA or scheduling a road test. '\n",
    "- 'About ten percent of customers visiting a DMV office do not bring what they need to complete their transaction, and have to come back a second time to finish their business. This can be as simple as not bringing sufficient funds to pay for a license renewal or not having the proof of auto insurance required to register a car. don t visit a DMV office at all, and see if your transaction can be performed online, like an address change, registration renewal, license renewal, replacing a lost title, paying a DRA or scheduling a road test. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90bfaf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_sep_tokens(windows):\n",
    "    tmp = []\n",
    "    sep_token = 102\n",
    "    for window in windows:\n",
    "        end = len(window) - 1\n",
    "        if window[end] != sep_token:\n",
    "            # remove final value, add a SEP\n",
    "            window = window[0:-1]\n",
    "            tmp.append(torch.cat((window, torch.tensor([102])),0))\n",
    "        else:\n",
    "            tmp.append(window)\n",
    "    return tmp\n",
    "\n",
    "def sliding_windows(question, document, stride=256):\n",
    "    # tokenized input_ids is the document - remove [CLS] before sending through\n",
    "    windows = []\n",
    "    model_tok_limit = 512  # model can take 512 tokens maximum\n",
    "    start = 0\n",
    "    end = model_tok_limit - len(question)\n",
    "    doc_size = len(document)\n",
    "        \n",
    "    # handling edge case of documents smaller than models input (512 tokens)   \n",
    "    if len(document) <= model_tok_limit:\n",
    "        end = len(document)\n",
    "    \n",
    "    while(start <= doc_size):\n",
    "        # print(start, end, doc_size)\n",
    "        window = document[start:end]\n",
    "        windows.append(window)\n",
    "        \n",
    "        if end == doc_size: \n",
    "            break\n",
    "        \n",
    "        start += stride\n",
    "        # if there are less tokens than the slide amount\n",
    "        if (doc_size - (start + stride)) < stride:\n",
    "            end = doc_size\n",
    "        else:\n",
    "            end += stride\n",
    "    \n",
    "    windows = add_sep_tokens(windows)\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b07c048",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Sliding Window [1:] to remove the [CLS] that was put in by the tokenizer\n",
    "    The Model likes '[CLS] Sentence1 [SEP] Sentence2 [SEP]' it doesn't need the [CLS]\n",
    "'''\n",
    "\n",
    "windows = sliding_windows(question, text['input_ids'][0][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92fb1f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = []\n",
    "\n",
    "for window in windows:\n",
    "    model_inputs.append(text_mask(question, window))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01cad9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] hello, i forgot o update my address, can you help me with that? [SEP] many dmv customers make easily avoidable mistakes that cause them significant problems, including encounters with law enforcement and impounded vehicles. because we see customers make these mistakes over and over again, we are issuing this list of the top five dmv mistakes and how to avoid them. 1. forgetting to update address by statute, you must report a change of address to dmv within ten days of moving. that is the case for the address associated with your license, as well as all the addresses associated with each registered vehicle, which may differ. it is not sufficient to only : write your new address on the back of your old license ; tell the united states postal service ; or inform the police officer writing you a ticket. if you fail to keep your address current, you will miss a suspension order and may be charged with operating an unregistered vehicle and / or aggravated unlicensed operation, both misdemeanors. this really happens, but the good news is this is a problem that is easily avoidable. learn more about how to change the address on your license and registrations [ 1 ] 2. leaving the state without notifying dmv states communicate with each other, so when you move to another state, be sure to tie up any loose ends regarding your new york state license or registration. that means resolving any unanswered tickets, suspensions or revocations, and surrendering your license plates to nys when you get to your new home state. a license suspension or revocation here could mean that your new home state will not issue you a license there. remember, it is important to notify dmv of your new address so that any possible mail correspondence can reach you. also, turning in your plates is important to avoid an insurance lapse. 3. letting insurance lapse because we all pay indirectly for crashes involving uninsured motorists, new york state requires every motorist to maintain auto insurance every single day a vehicle is registered. dmv works with insurance companies to electronically monitor your insurance coverage, and we know when coverage is dropped for any reason. when that happens, we mail you an insurance inquiry letter to allow you to clear up the problem. we send 500, 000 inquiry letters a year. if the inquiry letter does not resolve the problem, we must suspend the vehicle registration and, if it persists, your driver license! we suspend 300, 000 registrations [SEP]\n",
      "[CLS] hello, i forgot o update my address, can you help me with that? [SEP] any loose ends regarding your new york state license or registration. that means resolving any unanswered tickets, suspensions or revocations, and surrendering your license plates to nys when you get to your new home state. a license suspension or revocation here could mean that your new home state will not issue you a license there. remember, it is important to notify dmv of your new address so that any possible mail correspondence can reach you. also, turning in your plates is important to avoid an insurance lapse. 3. letting insurance lapse because we all pay indirectly for crashes involving uninsured motorists, new york state requires every motorist to maintain auto insurance every single day a vehicle is registered. dmv works with insurance companies to electronically monitor your insurance coverage, and we know when coverage is dropped for any reason. when that happens, we mail you an insurance inquiry letter to allow you to clear up the problem. we send 500, 000 inquiry letters a year. if the inquiry letter does not resolve the problem, we must suspend the vehicle registration and, if it persists, your driver license! we suspend 300, 000 registrations a year for failure to maintain insurance. if you fail to maintain an updated address with us, you won t learn that you have an insurance problem, and we will suspend your registration and license. make sure you turn in your vehicle s license plates at dmv before you cancel your insurance policy. insurance policies must be from a company licensed in new york state. learn more about insurances lapes [ 2 ] and how to surrender your plates [ 3 ] 4. understanding how much traffic points cost dmv maintains a point system to track dangerous drivers. often, motorists convicted of a traffic ticket feel they have resolved all their motoring issues with the local court, but later learn that the driver responsibility assessment dra is a separate dmv charge based on the total points they accumulate. the $ 300 dra fee can be paid in $ 100 annual installments over three years. motorists who fail to maintain an updated address with dmv may resolve their tickets with the court, but never receive their dra assessment because we don't have their new address on record. failure to pay the dra will result in a suspended license. learn more about about the nys driver point system [ 4 ] and how to pay driver responsibility assessment [ 5 ] 5. [SEP]\n",
      "[CLS] hello, i forgot o update my address, can you help me with that? [SEP] you won t learn that you have an insurance problem, and we will suspend your registration and license. make sure you turn in your vehicle s license plates at dmv before you cancel your insurance policy. insurance policies must be from a company licensed in new york state. learn more about insurances lapes [ 2 ] and how to surrender your plates [ 3 ] 4. understanding how much traffic points cost dmv maintains a point system to track dangerous drivers. often, motorists convicted of a traffic ticket feel they have resolved all their motoring issues with the local court, but later learn that the driver responsibility assessment dra is a separate dmv charge based on the total points they accumulate. the $ 300 dra fee can be paid in $ 100 annual installments over three years. motorists who fail to maintain an updated address with dmv may resolve their tickets with the court, but never receive their dra assessment because we don't have their new address on record. failure to pay the dra will result in a suspended license. learn more about about the nys driver point system [ 4 ] and how to pay driver responsibility assessment [ 5 ] 5. not bringing proper documentation to dmv office about ten percent of customers visiting a dmv office don't bring what they need to complete their transaction, and have to come back a second time to finish their business. this can be as simple as not bringing sufficient funds to pay for a license renewal or not having the proof of auto insurance required to register a car. better yet, don t visit a dmv office at all, and see if your transaction can be performed online, like an address change, registration renewal, license renewal, replacing a lost title, paying a dra or scheduling a road test. our award - winning website is recognized as one of the best in the nation. it has all the answers you need to efficiently perform any dmv transaction. consider signing up for our mydmv service, which offers even more benefits. sign up or log into mydmv [ 6 ] [SEP]\n"
     ]
    }
   ],
   "source": [
    "for model_input in model_inputs:\n",
    "    print(tokenizer.decode(model_input[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ac7644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae82c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
